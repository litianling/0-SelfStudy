{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import Overlay\n",
    "overlay = Overlay(\"./bit/forw_back.bit\")  # ./bit/forw_back.bit  和  ./bit/model.bit\n",
    "core = overlay.forw_back_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(flag, in_d, conv1, conv2, conv3, fc1, fc2, fc3, out, label, lr):    # 向PL端口输入数据\n",
    "    core.write(0x10, flag)      # 地址可在HLS下solution1/impl/misc/drivers/forw_back_v0_0/src/xforw_back_hw.h可查\n",
    "    core.write(0x18, in_d)      # 地址也可在SDK下system.hdf文件IP blocks present in the design部分Registers可查\n",
    "    core.write(0x20, conv1)\n",
    "    core.write(0x28, conv2)\n",
    "    core.write(0x30, conv3)\n",
    "    core.write(0x38, fc1)\n",
    "    core.write(0x40, fc2)\n",
    "    core.write(0x48, fc3)\n",
    "    core.write(0x50, out)\n",
    "    core.write(0x58, label)\n",
    "    core.write(0x60, lr)\n",
    "    core.write(0x00, 0x01)\n",
    "    while(core.read(0x00)!=4):  # 如果0x00!=4就代表PL端还在运行\n",
    "        i = 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max10(data):                # 取最大值函数\n",
    "    for i in range(10):\n",
    "        if(data[i] == max(data)):\n",
    "            location = i\n",
    "            break\n",
    "    return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import Xlnk\n",
    "import numpy as np\n",
    "\n",
    "xlnk = Xlnk()       # 该接口必须申请内存后才能被IP使用，可以使用xlnk来申请一段连续内存缓冲区，该缓冲区允许PS跟PL之间进行有效的数据传输"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 给每个接口分配空间\n",
    "data_in = xlnk.cma_array(shape=(30*30,), dtype=np.float32)\n",
    "conv1 = xlnk.cma_array(shape=(9,), dtype=np.float32)\n",
    "conv2 = xlnk.cma_array(shape=(9,), dtype=np.float32)\n",
    "conv3 = xlnk.cma_array(shape=(9,), dtype=np.float32)\n",
    "fc1 = xlnk.cma_array(shape=(576*180,), dtype=np.float32)\n",
    "fc2 = xlnk.cma_array(shape=(180*45,), dtype=np.float32)\n",
    "fc3 = xlnk.cma_array(shape=(45*10,), dtype=np.float32)\n",
    "data_out = xlnk.cma_array(shape=(10,), dtype=np.float32)\n",
    "lr = xlnk.cma_array(shape=(1,), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from struct import unpack\n",
    "\n",
    "para = open(\"./Network_parameter.bin\", \"rb\")\n",
    "conv1_f = []\n",
    "conv2_f = []\n",
    "conv3_f = []\n",
    "fc1_f = []\n",
    "fc2_f = []\n",
    "fc3_f = []\n",
    "\n",
    "# 读取卷积核参数\n",
    "for i in range(9):\n",
    "    data = para.read(4)\n",
    "    conv1_f.append(unpack(\"f\", data)[0])\n",
    "\n",
    "for i in range(9):\n",
    "    data = para.read(4)\n",
    "    conv2_f.append(unpack(\"f\", data)[0])\n",
    "\n",
    "for i in range(9):\n",
    "    data = para.read(4)\n",
    "    conv3_f.append(unpack(\"f\", data)[0])\n",
    "\n",
    "# 读取全连接系数矩阵参数\n",
    "for i in range(576*180):\n",
    "    data = para.read(4)\n",
    "    fc1_f.append(unpack(\"f\", data)[0])\n",
    "    \n",
    "for i in range(180*45):\n",
    "    data = para.read(4)\n",
    "    fc2_f.append(unpack(\"f\", data)[0])\n",
    "    \n",
    "for i in range(45*10):\n",
    "    data = para.read(4)\n",
    "    fc3_f.append(unpack(\"f\", data)[0])\n",
    "\n",
    "# 处理\n",
    "for k in range(9):\n",
    "    conv1[k] = conv1_f[k]\n",
    "    conv2[k] = conv2_f[k]\n",
    "    conv3[k] = conv3_f[k]\n",
    "for k in range(576*180):\n",
    "    fc1[k] = fc1_f[k]\n",
    "for k in range(180*45):\n",
    "    fc2[k] = fc2_f[k]\n",
    "for k in range(45*10):\n",
    "    fc3[k] = fc3_f[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取图片标签和数据\n",
    "img_label = []\n",
    "for i in range(10):\n",
    "    for j in range(30):\n",
    "        img_label.append(i)\n",
    "\n",
    "img_data = []\n",
    "def data_loader(path):\n",
    "    for i in range(10):                                 # 遍历分组\n",
    "        imgs_path = path + '/'+ str(i) + '/'\n",
    "        for j in range(30):                             # 遍历图片\n",
    "            img_path = imgs_path + str(j + 1) + '.bmp'\n",
    "            img = open(img_path, 'rb')\n",
    "            img.seek(62)                                 # 跳过前62个没用的字节\n",
    "            nums = []\n",
    "            and_list = [1, 2, 4, 8, 16, 32, 64, 128]     # 辅助从字节中提取比特\n",
    "            for i in range(120):                        \n",
    "                num = unpack(\"B\", img.read(1))[0]        # 从头开始逐一读取120个字节\n",
    "                for j in range(8):                      # 遍历8个bit\n",
    "                    if (i % 4 == 3) and (j >= 6):       # 检测到两个多余bit就跳过\n",
    "                        continue\n",
    "                    nums.append(int((num & and_list[7 - j]) == and_list[7 - j]))  # 真实数据就放到列表后面\n",
    "            img_data.append(nums[:])\n",
    "            \n",
    "data_loader(\"./Training_set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# print(len(img_data))\n",
    "corss_loss_max = 2\n",
    "for epoch in range(5):\n",
    "    lr[0] = pow((corss_loss_max/10), 1.7)\n",
    "    if lr[0] > 0.01:\n",
    "        lr[0] = 0.01\n",
    "    if lr[0] < 0.0000000001:\n",
    "        break\n",
    "    \n",
    "    # 不打乱反而会使损失增大\n",
    "    img_data_change = []\n",
    "    img_label_change = 0\n",
    "    label_1 = 0\n",
    "    label_2 = 0\n",
    "    for i in range(300):\n",
    "        label_1 = np.random.randint(0,299)\n",
    "        label_2 = np.random.randint(0,299)\n",
    "        if label_1 != label_2:\n",
    "            img_data_change = img_data[label_1]\n",
    "            img_data[label_1] = img_data[label_2]\n",
    "            img_data[label_2] = img_data_change\n",
    "            img_label_change = img_label[label_1]\n",
    "            img_label[label_1] = img_label[label_2]\n",
    "            img_label[label_2] = img_label_change\n",
    "        \n",
    "    \n",
    "    for i in range(300):\n",
    "        corss_loss_max = 0\n",
    "        for j in range(30*30):\n",
    "            data_in[j] = img_data[i][j]\n",
    "        net(1, data_in.physical_address, conv1.physical_address, conv2.physical_address, conv3.physical_address, fc1.physical_address, fc2.physical_address, fc3.physical_address, data_out.physical_address, img_label[i], lr.physical_address)\n",
    "        # print(conv1[0],conv1[1],conv1[2],conv1[3],conv1[4],conv1[5],conv1[6],conv1[7],conv1[8])\n",
    "        # print(fc3[0],fc3[1],fc3[2],fc3[3],fc3[4],fc3[5],fc3[6],fc3[7],fc3[8])\n",
    "        corss_loss_current = -(math.log10(data_out[img_label[i]]))\n",
    "        if corss_loss_current > corss_loss_max:\n",
    "            corss_loss_max = corss_loss_current\n",
    "        \n",
    "    print(corss_loss_max,lr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from struct import unpack\n",
    "\n",
    "# 随机初始化网络参数\n",
    "conv1_f = np.random.randn(9)\n",
    "conv2_f = np.random.randn(9) / 5\n",
    "conv3_f = np.random.randn(9) / 5\n",
    "fc1_f = np.random.randn(576*180) / 1000\n",
    "fc2_f = np.random.randn(180*45) / 100\n",
    "fc3_f = np.random.randn(45*10) / 10\n",
    "\n",
    "# 处理\n",
    "for k in range(9):\n",
    "    conv1[k] = conv1_f[k]\n",
    "    conv2[k] = conv2_f[k]\n",
    "    conv3[k] = conv3_f[k]\n",
    "\n",
    "for k in range(576*180):\n",
    "    fc1[k] = fc1_f[k]\n",
    "\n",
    "for k in range(180*45):\n",
    "    fc2[k] = fc2_f[k]\n",
    "\n",
    "for k in range(45*10):\n",
    "    fc3[k] = fc3_f[k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
